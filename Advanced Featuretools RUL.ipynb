{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Remaining Useful Life (advanced)\n",
    "<p style=\"margin:30px\">\n",
    "    <img style=\"display:inline; margin-right:50px\" width=50% src=\"https://www.featuretools.com/wp-content/uploads/2017/12/FeatureLabs-Logo-Tangerine-800.png\" alt=\"Featuretools\" />\n",
    "    <img style=\"display:inline\" width=15% src=\"https://upload.wikimedia.org/wikipedia/commons/e/e5/NASA_logo.svg\" alt=\"NASA\" />\n",
    "</p>\n",
    "\n",
    "This notebook has a more advanced workflow than [the other notebook](Simple%20Featuretools%20RUL%20Demo.ipynb) for predicting Remaining Useful Life (RUL). If you are a new to either this dataset or Featuretools, I would recommend reading the other notebook first. \n",
    "\n",
    "*If you're running this notebook yourself, please [download](https://ti.arc.nasa.gov/c/13/) the dataset into the `data` folder in this repository.*\n",
    "\n",
    "## Highlights\n",
    "* Demonstrate how novel entityset structures improve predictive accuracy\n",
    "* Build custom primitives using time-series functions from [tsfresh](https://github.com/blue-yonder/tsfresh)\n",
    "* Improve Mean Absolute Error by tuning hyper parameters with [BTB](https://github.com/HDI-Project/BTB)\n",
    "\n",
    "Here is a collection of scores from a run of both notebooks. Because of the randomness in the Random Forest Regressor and how we choose labels from the Train data, scores are subject to change.\n",
    "\n",
    "|                                 | Train |  Test |\n",
    "|---------------------------------|---------------|\n",
    "| Median Baseline                 | 62.55 | 50.55 |\n",
    "| Simple Featuretools             | 41.18 | 39.56 |\n",
    "| Advanced: Custom Primitives     | 39.55 | 41.02 |\n",
    "| Advanced: Hyperparameter Tuning | 27.63 | 13.36 |\n",
    "\n",
    "\n",
    "# Step 1: Load Data\n",
    "Here we load in the train data using the same function we used in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_no</th>\n",
       "      <th>time_in_cycles</th>\n",
       "      <th>operational_setting_1</th>\n",
       "      <th>operational_setting_2</th>\n",
       "      <th>operational_setting_3</th>\n",
       "      <th>sensor_measurement_1</th>\n",
       "      <th>sensor_measurement_2</th>\n",
       "      <th>sensor_measurement_3</th>\n",
       "      <th>sensor_measurement_4</th>\n",
       "      <th>sensor_measurement_5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_measurement_14</th>\n",
       "      <th>sensor_measurement_15</th>\n",
       "      <th>sensor_measurement_16</th>\n",
       "      <th>sensor_measurement_17</th>\n",
       "      <th>sensor_measurement_18</th>\n",
       "      <th>sensor_measurement_19</th>\n",
       "      <th>sensor_measurement_20</th>\n",
       "      <th>sensor_measurement_21</th>\n",
       "      <th>index</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0049</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>549.68</td>\n",
       "      <td>1343.43</td>\n",
       "      <td>1112.93</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>8074.83</td>\n",
       "      <td>9.3335</td>\n",
       "      <td>0.02</td>\n",
       "      <td>330</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.62</td>\n",
       "      <td>6.3670</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0020</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>491.19</td>\n",
       "      <td>606.07</td>\n",
       "      <td>1477.61</td>\n",
       "      <td>1237.50</td>\n",
       "      <td>9.35</td>\n",
       "      <td>...</td>\n",
       "      <td>8046.13</td>\n",
       "      <td>9.1913</td>\n",
       "      <td>0.02</td>\n",
       "      <td>361</td>\n",
       "      <td>2324</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24.37</td>\n",
       "      <td>14.6552</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-01 00:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0038</td>\n",
       "      <td>0.8409</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>548.95</td>\n",
       "      <td>1343.12</td>\n",
       "      <td>1117.05</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>8066.62</td>\n",
       "      <td>9.4007</td>\n",
       "      <td>0.02</td>\n",
       "      <td>329</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.48</td>\n",
       "      <td>6.4213</td>\n",
       "      <td>2</td>\n",
       "      <td>2000-01-01 00:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>548.70</td>\n",
       "      <td>1341.24</td>\n",
       "      <td>1118.03</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>8076.05</td>\n",
       "      <td>9.3369</td>\n",
       "      <td>0.02</td>\n",
       "      <td>328</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.54</td>\n",
       "      <td>6.4176</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-01-01 00:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>25.0063</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>60.0</td>\n",
       "      <td>462.54</td>\n",
       "      <td>536.10</td>\n",
       "      <td>1255.23</td>\n",
       "      <td>1033.59</td>\n",
       "      <td>7.05</td>\n",
       "      <td>...</td>\n",
       "      <td>7865.80</td>\n",
       "      <td>10.8366</td>\n",
       "      <td>0.02</td>\n",
       "      <td>305</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93</td>\n",
       "      <td>14.03</td>\n",
       "      <td>8.6754</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-01-01 00:00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       engine_no  time_in_cycles  operational_setting_1  \\\n",
       "index                                                     \n",
       "0              1               1                42.0049   \n",
       "1              1               2                20.0020   \n",
       "2              1               3                42.0038   \n",
       "3              1               4                42.0000   \n",
       "4              1               5                25.0063   \n",
       "\n",
       "       operational_setting_2  operational_setting_3  sensor_measurement_1  \\\n",
       "index                                                                       \n",
       "0                     0.8400                  100.0                445.00   \n",
       "1                     0.7002                  100.0                491.19   \n",
       "2                     0.8409                  100.0                445.00   \n",
       "3                     0.8400                  100.0                445.00   \n",
       "4                     0.6207                   60.0                462.54   \n",
       "\n",
       "       sensor_measurement_2  sensor_measurement_3  sensor_measurement_4  \\\n",
       "index                                                                     \n",
       "0                    549.68               1343.43               1112.93   \n",
       "1                    606.07               1477.61               1237.50   \n",
       "2                    548.95               1343.12               1117.05   \n",
       "3                    548.70               1341.24               1118.03   \n",
       "4                    536.10               1255.23               1033.59   \n",
       "\n",
       "       sensor_measurement_5         ...          sensor_measurement_14  \\\n",
       "index                               ...                                  \n",
       "0                      3.91         ...                        8074.83   \n",
       "1                      9.35         ...                        8046.13   \n",
       "2                      3.91         ...                        8066.62   \n",
       "3                      3.91         ...                        8076.05   \n",
       "4                      7.05         ...                        7865.80   \n",
       "\n",
       "       sensor_measurement_15  sensor_measurement_16  sensor_measurement_17  \\\n",
       "index                                                                        \n",
       "0                     9.3335                   0.02                    330   \n",
       "1                     9.1913                   0.02                    361   \n",
       "2                     9.4007                   0.02                    329   \n",
       "3                     9.3369                   0.02                    328   \n",
       "4                    10.8366                   0.02                    305   \n",
       "\n",
       "       sensor_measurement_18  sensor_measurement_19  sensor_measurement_20  \\\n",
       "index                                                                        \n",
       "0                       2212                 100.00                  10.62   \n",
       "1                       2324                 100.00                  24.37   \n",
       "2                       2212                 100.00                  10.48   \n",
       "3                       2212                 100.00                  10.54   \n",
       "4                       1915                  84.93                  14.03   \n",
       "\n",
       "       sensor_measurement_21  index                time  \n",
       "index                                                    \n",
       "0                     6.3670      0 2000-01-01 00:00:00  \n",
       "1                    14.6552      1 2000-01-01 00:00:01  \n",
       "2                     6.4213      2 2000-01-01 00:00:02  \n",
       "3                     6.4176      3 2000-01-01 00:00:03  \n",
       "4                     8.6754      4 2000-01-01 00:00:04  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "import utils\n",
    "\n",
    "data_path = 'data/RUL_train.txt'\n",
    "data = utils.load_data(data_path)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also make cutoff times by selecting a random cutoff time from the life of each engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_no</th>\n",
       "      <th>cutoff_time</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-01 00:04:05</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2000-01-01 00:05:43</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2000-01-01 00:11:14</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2000-01-01 00:19:27</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2000-01-01 00:20:30</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       engine_no         cutoff_time  RUL\n",
       "index                                    \n",
       "1              1 2000-01-01 00:04:05   75\n",
       "2              2 2000-01-01 00:05:43  276\n",
       "3              3 2000-01-01 00:11:14  252\n",
       "4              4 2000-01-01 00:19:27   33\n",
       "5              5 2000-01-01 00:20:30  163"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_times = utils.make_cutoff_times(data)\n",
    "\n",
    "cutoff_times.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to do something fancy for our entityset. The values for `operational_setting` 1-3 are continuous but create an implicit relation between different engines. If two engines have a similar `operational_setting`, it could indicate that we should expect the sensor measurements to mean similar things. We make clusters of those settings using `KMeans` from scikit-learn and make a new entity from the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: Dataset\n",
       "  Entities:\n",
       "    recordings (shape = [61249, 29])\n",
       "    cycles (shape = [543, 2])\n",
       "    settings_clusters (shape = [50, 2])\n",
       "    engines (shape = [249, 2])\n",
       "  Relationships:\n",
       "    recordings.engine_no -> engines.engine_no\n",
       "    recordings.time_in_cycles -> cycles.time_in_cycles\n",
       "    recordings.settings_clusters -> settings_clusters.settings_clusters"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "nclusters = 50\n",
    "\n",
    "def make_entityset(data, nclusters, kmeans=None):\n",
    "    X = data[['operational_setting_1', 'operational_setting_2', 'operational_setting_3']]\n",
    "    if kmeans:\n",
    "        kmeans=kmeans\n",
    "    else:\n",
    "        kmeans = KMeans(n_clusters=nclusters).fit(X)\n",
    "    data['settings_clusters'] = kmeans.predict(X)\n",
    "    \n",
    "    es = ft.EntitySet('Dataset')\n",
    "    es.entity_from_dataframe(dataframe=data,\n",
    "                             entity_id='recordings',\n",
    "                             index='index',\n",
    "                             time_index='time')\n",
    "\n",
    "    es.normalize_entity(base_entity_id='recordings', \n",
    "                        new_entity_id='engines',\n",
    "                        index='engine_no')\n",
    "    \n",
    "    es.normalize_entity(base_entity_id='recordings', \n",
    "                        new_entity_id='cycles',\n",
    "                        index='time_in_cycles')\n",
    "    \n",
    "    es.normalize_entity(base_entity_id='recordings', \n",
    "                        new_entity_id='settings_clusters',\n",
    "                        index='settings_clusters')\n",
    "    \n",
    "    return es, kmeans\n",
    "es, kmeans = make_entityset(data, nclusters)\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: DFS and Creating a Model\n",
    "In addition to changing our `EntitySet` structure, we're also going to use some time series primitives from the package [tsfresh](https://github.com/blue-yonder/tsfresh)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/featurelabs07/homeenv/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 1326 features\n",
      "Elapsed: 22:24 | Remaining: 00:00 | Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|| Calculated: 249/249 cutoff times\n"
     ]
    }
   ],
   "source": [
    "from tsfresh.feature_extraction.feature_calculators import number_peaks, mean_abs_change\n",
    "from featuretools.primitives import make_agg_primitive\n",
    "import featuretools.variable_types as vtypes\n",
    "\n",
    "def tsf_numpeaks(series):\n",
    "    return number_peaks(series, 3)\n",
    "\n",
    "MeanAbsChange = make_agg_primitive(mean_abs_change,\n",
    "                                   input_types=[vtypes.Numeric],\n",
    "                                   return_type=vtypes.Numeric,\n",
    "                                   name=\"mean_abs_change\")\n",
    "\n",
    "NumPeaks = make_agg_primitive(lambda x: number_peaks(x, 3),\n",
    "                              input_types=[vtypes.Numeric],\n",
    "                              return_type=vtypes.Numeric,\n",
    "                              name=\"number_peaks\")\n",
    "\n",
    "\n",
    "from featuretools.primitives import Sum, Mean, Std, Skew, Max, Min, Last, CumSum, Diff, Trend, Count\n",
    "fm, features = ft.dfs(entityset=es, \n",
    "                      target_entity='engines',\n",
    "                      agg_primitives=[Max, Min, Last, NumPeaks, MeanAbsChange],\n",
    "                      trans_primitives=[],\n",
    "                      cutoff_time=cutoff_times,\n",
    "                      max_depth=3,\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Feature Selection and Scoring\n",
    "Here, we'll use [Recursive Feature Elimination](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html). In order to set ourselves up for later optimization, we're going to write a generic `pipeline` function which takes in a set of hyperparameters and returns a score. Our pipeline will first run `RFE` and then split the remaining data for scoring by a `RandomForestRegressor`. We're going to pass in a list of hyperparameters, which we will tune later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Abs Error: 39.55\n",
      "1: NUMBER_PEAKS(recordings.settings_clusters.NUMBER_PEAKS(recordings.sensor_measurement_8)) [0.193]\n",
      "2: MAX(recordings.cycles.LAST(recordings.sensor_measurement_17)) [0.129]\n",
      "3: MAX(recordings.sensor_measurement_13) [0.081]\n",
      "4: MAX(recordings.cycles.LAST(recordings.sensor_measurement_11)) [0.078]\n",
      "5: NUMBER_PEAKS(recordings.settings_clusters.MIN(recordings.sensor_measurement_13)) [0.078]\n",
      "6: MAX(recordings.settings_clusters.LAST(recordings.sensor_measurement_3)) [0.057]\n",
      "7: MEAN_ABS_CHANGE(recordings.cycles.MIN(recordings.sensor_measurement_7)) [0.037]\n",
      "8: MAX(recordings.cycles.LAST(recordings.sensor_measurement_15)) [0.036]\n",
      "9: MAX(recordings.settings_clusters.LAST(recordings.sensor_measurement_13)) [0.035]\n",
      "10: MAX(recordings.settings_clusters.LAST(recordings.sensor_measurement_4)) [0.031]\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "def pipeline(X, y, hyperparams):\n",
    "    \"\"\" Hyperparams: [\n",
    "            0: number of estimators for the random forest in RFE\n",
    "            1: number of features to select\n",
    "            2: number of estimators for  random forest in scoring\n",
    "            3: max feats for random forest in scoring\n",
    "        ]\n",
    "    \"\"\"\n",
    "    reg = RandomForestRegressor(n_estimators=int(hyperparams[0]), n_jobs=3)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    selector = RFE(reg, int(hyperparams[1]), step=50)\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "    max_feats = min(hyperparams[3], hyperparams[1])\n",
    "    reg = RandomForestRegressor(n_estimators=int(hyperparams[2]), \n",
    "                                max_features=int(max_feats))\n",
    "    reg.fit(selector.transform(X_train), y_train)\n",
    "    \n",
    "    preds = reg.predict(selector.transform(X_test))\n",
    "    score = mean_absolute_error(preds, y_test)\n",
    "    return score, (selector, reg)\n",
    "\n",
    "X = fm.copy().fillna(0)\n",
    "y = X.pop('RUL')\n",
    "\n",
    "rfe_nest = 10\n",
    "nfeats = 30\n",
    "sco_nest = 10\n",
    "sco_maxfeats = 20\n",
    "\n",
    "hyperparams = [rfe_nest, nfeats, sco_nest, sco_maxfeats]\n",
    "score, (selector, model) = pipeline(X, y, hyperparams)\n",
    "\n",
    "print('Mean Abs Error: {:.2f}'.format(score))\n",
    "high_imp_feats = utils.feature_importances(X.iloc[:, selector.support_], model, feats=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can use that selector and regressor to score the test values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 00:59 | Remaining: 00:00 | Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|| Calculated: 1/1 cutoff times\n",
      "Mean Abs Error: 41.02\n"
     ]
    }
   ],
   "source": [
    "data2 = utils.load_data('data/RUL_test.txt')\n",
    "\n",
    "es2, _ = make_entityset(data2, nclusters, kmeans=kmeans)\n",
    "fm2 = ft.calculate_feature_matrix(entityset=es2, features=features, verbose=True)\n",
    "X = fm2.copy().fillna(0)\n",
    "y = pd.read_csv('data/RUL_test_truth.txt', sep=' ', header=-1, names=['RUL'], index_col=False)\n",
    "preds2 = model.predict(selector.transform(X))\n",
    "print('Mean Abs Error: {:.2f}'.format(mean_absolute_error(preds2, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Hyperparameter Tuning\n",
    "Because of the way we set up our pipeline, we can use a Gaussian Process to tune the hyperparameters. We will use [BTB](https://github.com/HDI-Project/BTB) from the [HDI Project](https://github.com/HDI-Project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sel_n_est, sel_n_feats, model_n_est, model_max_feats]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|â–Ž         | 1/30 [01:30<43:38, 90.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192.  46. 212.  20.]: New best score of 31.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [47:24<1:21:53, 258.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[968.  14. 119.   5.]: New best score of 29.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [1:57:30<00:00, 235.02s/it]  \n"
     ]
    }
   ],
   "source": [
    "from btb.hyper_parameter import HyperParameter\n",
    "from btb.tuning.gp import GP\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_btb(X, y, n=30):\n",
    "    hyperparam_ranges = [\n",
    "            ('selector_n_estimators', HyperParameter('int', [100, 1000])),\n",
    "            ('select_n_features', HyperParameter('int', [5, 50])),\n",
    "            ('model_n_estimators', HyperParameter('int', [100, 500])),\n",
    "            ('model_max_feats', HyperParameter('int', [2, 20])),\n",
    "    ]\n",
    "    tuner = GP(hyperparam_ranges)\n",
    "\n",
    "    tested_parameters = np.zeros((n, len(hyperparam_ranges)), dtype=object)\n",
    "    scores = []\n",
    "    best = 100\n",
    "    \n",
    "    print('[sel_n_est, sel_n_feats, model_n_est, model_max_feats]')\n",
    "    for i in tqdm(range(n)):\n",
    "        tuner.fit(tested_parameters[:i, :], scores)\n",
    "        hyperparams = tuner.propose()\n",
    "\n",
    "        bound = -pipeline(X, y, hyperparams)[0]\n",
    "        tested_parameters[i, :] = hyperparams\n",
    "        scores.append(bound)\n",
    "        if -bound < best:\n",
    "            best = -bound\n",
    "            print('{}: New best score of {:.2f}'.format(hyperparams, -bound))\n",
    "    return tested_parameters, scores\n",
    "\n",
    "X = fm.copy().fillna(0)\n",
    "y = X.pop('RUL')\n",
    "\n",
    "tested_parameters, scores = run_btb(X, y, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/featurelabs07/homeenv/lib/python2.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/featurelabs07/homeenv/lib/python2.7/site-packages/ipykernel_launcher.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Abs Error on Train: 27.63\n",
      "1: MAX(recordings.sensor_measurement_11) [0.183]\n",
      "2: MAX(recordings.sensor_measurement_13) [0.156]\n",
      "3: MAX(recordings.sensor_measurement_4) [0.112]\n",
      "4: MAX(recordings.sensor_measurement_8) [0.093]\n",
      "5: MAX(recordings.sensor_measurement_3) [0.041]\n",
      "6: MAX(recordings.sensor_measurement_9) [0.031]\n",
      "7: MAX(recordings.sensor_measurement_2) [0.025]\n",
      "8: MEAN_ABS_CHANGE(recordings.cycles.NUMBER_PEAKS(recordings.operational_setting_1)) [0.024]\n",
      "9: MAX(recordings.sensor_measurement_14) [0.023]\n",
      "10: LAST(recordings.cycles.MAX(recordings.sensor_measurement_11)) [0.017]\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyperparams = [192.,  46., 212.,  20.]\n",
    "score, (selector, model) = pipeline(X, y, hyperparams)\n",
    "\n",
    "print('Mean Abs Error on Train: {:.2f}'.format(score))\n",
    "high_imp_feats = utils.feature_importances(X.iloc[:, selector.support_], model, feats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Abs Error on Test: 13.36\n"
     ]
    }
   ],
   "source": [
    "X = fm2.copy().fillna(0)\n",
    "y = pd.read_csv('data/RUL_test_truth.txt', sep=' ', header=-1, names=['RUL'], index_col=False)\n",
    "\n",
    "preds2 = model.predict(selector.transform(X))\n",
    "score2 = mean_absolute_error(preds2, y)\n",
    "print('Mean Abs Error on Test: {:.2f}'.format(score2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
