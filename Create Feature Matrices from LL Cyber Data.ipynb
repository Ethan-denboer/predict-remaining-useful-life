{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft\n",
    "from featuretools.primitives import CumMean, Percentile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyber_df = pd.read_csv(\"CyberFLTenDays.csv\").sample(1000)\n",
    "cyber_df.index.name = \"log_id\"\n",
    "cyber_df.reset_index(inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: CyberLL\n",
       "  Entities:\n",
       "    log (shape = [1000, 7])\n",
       "    name_host_pairs (shape = [943, 5])\n",
       "    src_pairs (shape = [913, 4])\n",
       "    src_names (shape = [814, 2])\n",
       "    src_hosts (shape = [487, 2])\n",
       "    ...And 3 more\n",
       "  Relationships:\n",
       "    log.name_host_pair -> name_host_pairs.name_host_pair\n",
       "    name_host_pairs.src_pair -> src_pairs.src_pair\n",
       "    src_pairs.src_name -> src_names.src_name\n",
       "    src_pairs.src_host -> src_hosts.src_host\n",
       "    name_host_pairs.dest_pair -> dest_pairs.dest_pair\n",
       "    ...and 2 more"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = ft.EntitySet(\"CyberLL\")\n",
    "# create an index column\n",
    "cyber_df[\"name_host_pair\"] = cyber_df[\"src_name\"].str.cat(\n",
    "                                [cyber_df[\"dest_name\"],\n",
    "                                 cyber_df[\"src_host\"],\n",
    "                                 cyber_df[\"dest_host\"]],\n",
    "                                sep=' / ')\n",
    "cyber_df[\"src_pair\"] = cyber_df[\"src_name\"].str.cat(\n",
    "                                 cyber_df[\"src_host\"],\n",
    "                                 sep=' / ')\n",
    "cyber_df[\"dest_pair\"] = cyber_df[\"dest_name\"].str.cat(\n",
    "                                 cyber_df[\"dest_host\"],\n",
    "                                 sep=' / ')\n",
    "es.entity_from_dataframe(\"log\",\n",
    "                         cyber_df,\n",
    "                         index=\"log_id\",\n",
    "                         time_index=\"secs\")\n",
    "es.normalize_entity(base_entity_id=\"log\",\n",
    "                    new_entity_id=\"name_host_pairs\",\n",
    "                    index=\"name_host_pair\",\n",
    "                    additional_variables=[\"src_name\", \"dest_name\",\n",
    "                                          \"src_host\", \"dest_host\",\n",
    "                                          \"src_pair\",\n",
    "                                          \"dest_pair\",\n",
    "                                          \"label\"])\n",
    "es.normalize_entity(base_entity_id=\"name_host_pairs\",\n",
    "                    new_entity_id=\"src_pairs\",\n",
    "                    index=\"src_pair\",\n",
    "                    additional_variables=[\"src_name\", \"src_host\"])\n",
    "es.normalize_entity(base_entity_id=\"src_pairs\",\n",
    "                    new_entity_id=\"src_names\",\n",
    "                    index=\"src_name\")\n",
    "es.normalize_entity(base_entity_id=\"src_pairs\",\n",
    "                    new_entity_id=\"src_hosts\",\n",
    "                    index=\"src_host\")\n",
    "es.normalize_entity(base_entity_id=\"name_host_pairs\",\n",
    "                    new_entity_id=\"dest_pairs\",\n",
    "                    index=\"dest_pair\",\n",
    "                    additional_variables=[\"dest_name\", \"dest_host\"])\n",
    "es.normalize_entity(base_entity_id=\"dest_pairs\",\n",
    "                    new_entity_id=\"dest_names\",\n",
    "                    index=\"dest_name\")\n",
    "es.normalize_entity(base_entity_id=\"dest_pairs\",\n",
    "                    new_entity_id=\"dest_hosts\",\n",
    "                    index=\"dest_host\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cutoffs(cyber_df, index_col, after_n_obs):\n",
    "    grouped = cyber_df.groupby(index_col)[index_col].count()\n",
    "    grouped.name = \"count\"\n",
    "    enough_examples = grouped[grouped > after_n_obs].to_frame().reset_index()\n",
    "    enough_examples = cyber_df[cyber_df[index_col].isin(enough_examples[index_col])]\n",
    "    cutoffs = enough_examples.groupby(index_col)[[index_col, \"secs\"]].apply(lambda x: x.iloc[after_n_obs])\n",
    "    return cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict after 3 observations\n",
    "after_n_obs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 388 features\n",
      "Elapsed: 00:10 | Remaining: 00:00 | Progress: 100%|██████████|| Calculated: 17/17 cutoff times\n"
     ]
    }
   ],
   "source": [
    "# features on src_name\n",
    "cutoffs = generate_cutoffs(cyber_df, \"src_name\", after_n_obs)\n",
    "fm, fl = ft.dfs(entityset=es, target_entity=\"src_names\", cutoff_time=cutoffs, verbose=True, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 388 features\n",
      "Elapsed: 00:20 | Remaining: 00:00 | Progress: 100%|██████████|| Calculated: 31/31 cutoff times\n"
     ]
    }
   ],
   "source": [
    "## features on src_host\n",
    "cutoffs = generate_cutoffs(cyber_df, \"src_host\", after_n_obs)\n",
    "fm, fl = ft.dfs(entityset=es, target_entity=\"src_hosts\", cutoff_time=cutoffs, verbose=True, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 388 features\n",
      "Elapsed: 00:09 | Remaining: 00:00 | Progress: 100%|██████████|| Calculated: 16/16 cutoff times\n"
     ]
    }
   ],
   "source": [
    "## features on dest_name\n",
    "cutoffs = generate_cutoffs(cyber_df, \"dest_name\", after_n_obs)\n",
    "fm, fl = ft.dfs(entityset=es, target_entity=\"dest_names\", cutoff_time=cutoffs, verbose=True, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 388 features\n",
      "Elapsed: 00:21 | Remaining: 00:00 | Progress: 100%|██████████|| Calculated: 30/30 cutoff times\n"
     ]
    }
   ],
   "source": [
    "## features on dest_host\n",
    "cutoffs = generate_cutoffs(cyber_df, \"dest_host\", after_n_obs)\n",
    "fm, fl = ft.dfs(entityset=es, target_entity=\"dest_hosts\", cutoff_time=cutoffs, verbose=True, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 59 features\n",
      "Elapsed: 00:02 | Remaining: 00:00 | Progress: 100%|██████████|| Calculated: 5/5 cutoff times\n"
     ]
    }
   ],
   "source": [
    "# features on src_name/dest_name/src_host/dest_host\n",
    "cutoffs = generate_cutoffs(cyber_df, \"name_host_pair\", after_n_obs)\n",
    "fm, fl = ft.dfs(entityset=es, target_entity=\"name_host_pairs\", cutoff_time=cutoffs, verbose=True, max_depth=2, trans_primitives=[CumMean, Percentile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge entities together to access the index variables created in the process of normalizing\n",
    "merged = (es['log'].df\n",
    "                   .merge(es['name_host_pairs'].df)\n",
    "                   .merge(es['src_pairs'].df)\n",
    "                   .merge(es['dest_pairs'].df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 123 features\n",
      "Elapsed: 00:03 | Remaining: 00:00 | Progress: 100%|██████████|| Calculated: 3/3 cutoff times\n"
     ]
    }
   ],
   "source": [
    "# features on src_name/src_host\n",
    "cutoffs = generate_cutoffs(merged, 'src_pair', after_n_obs)\n",
    "fm, fl = ft.dfs(entityset=es, target_entity=\"src_pairs\", cutoff_time=cutoffs, verbose=True, max_depth=2, trans_primitives=[CumMean, Percentile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 123 features\n",
      "Elapsed: 00:03 | Remaining: 00:00 | Progress: 100%|██████████|| Calculated: 3/3 cutoff times\n"
     ]
    }
   ],
   "source": [
    "# features on dest_name/dest_host\n",
    "cutoffs = generate_cutoffs(merged, 'dest_pair', after_n_obs)\n",
    "fm, fl = ft.dfs(entityset=es, target_entity=\"dest_pairs\", cutoff_time=cutoffs, verbose=True, max_depth=2, trans_primitives=[CumMean, Percentile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
